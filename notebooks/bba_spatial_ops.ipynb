{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4fccbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       ".output {flex-direction: row}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    ".output {flex-direction: row}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ffffd9",
   "metadata": {},
   "source": [
    "# Räumliches Zusammenführen von Fahrradunfällen und Tempolimits/RVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3944e837",
   "metadata": {},
   "source": [
    "## Initialisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c6cd6",
   "metadata": {},
   "source": [
    "### Schritt 1.1: Import von Paketen und Definition von Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc48ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # ignore warnings\n",
    "\n",
    "\n",
    "def deriveSpeedLimit(row):\n",
    "    default = 50\n",
    "\n",
    "    if np.isnan(row['index_speed']) & np.isnan(row['index_road']):\n",
    "        # no intersection with roads or speed limits found\n",
    "        return None\n",
    "\n",
    "    if np.isnan(row['index_speed']):\n",
    "        # road without speed limit -> further check road rank\n",
    "        if row['rank'] == 3:\n",
    "            return default\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # check whether speed limit was already valid when accident occured\n",
    "    if row['dat_t'] is not None:\n",
    "        acc_date_str = f\"{row['UJAHR']}-{row['UMONAT']}-15\"\n",
    "        acc_dt = datetime.strptime(acc_date_str, '%Y-%m-%d')\n",
    "        if acc_dt < row['date']:\n",
    "            # -> speed limit not yet valid (date)\n",
    "            return default\n",
    "\n",
    "    # check day\n",
    "    if row['tag_t'] is not None:\n",
    "        if row['UWOCHENTAG'] < row['day_from'] or row['UWOCHENTAG'] > row['day_to']:\n",
    "            # -> speed limit not yet valid (day)\n",
    "            return default\n",
    "\n",
    "    # check time\n",
    "    if row['zeit_t'] is not None:\n",
    "        if row['time_from'] < row['time_to']:\n",
    "            # -> limit during day\n",
    "            if row['USTUNDE'] < row['time_from'] or row['USTUNDE'] >= row['time_to']:\n",
    "                # -> speed limit not yet valid (time)\n",
    "                return default\n",
    "        else:\n",
    "            # -> limit during night\n",
    "            if row['USTUNDE'] < row['time_from'] and row['USTUNDE'] >= row['time_to']:\n",
    "                # -> speed limit not yet valid (time)\n",
    "                return default\n",
    "\n",
    "    # -> valid speed limit determined!\n",
    "    return row['wert_ves']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd91b5",
   "metadata": {},
   "source": [
    "### Schritt 1.2: Laden der Konfiguration aus der `config.ini`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36bef4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read local config.ini file\n",
    "rel_path = './../'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(rel_path + 'config.ini')\n",
    "\n",
    "# get from config.ini\n",
    "dir_output = config['FILE_SETTINGS']['DIR_OUTPUT']\n",
    "gpkg_src = rel_path + dir_output + config['FILE_SETTINGS']['GPKG_NAME']\n",
    "gpkg_out = rel_path + dir_output + config['FILE_SETTINGS']['GPKG_NAME_BUF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0dad04",
   "metadata": {},
   "source": [
    "### Schritt 1.3: Laden der Unfalldaten\n",
    "\n",
    "Die Unfall-Rohdaten wurden im vorherigen Workflow-Schritt vorverarbeitet.\n",
    "\n",
    "Die Daten befinden sich im dafür erstellen GeoPackage `map_data.gpkg` mit folgenden Layern:\n",
    "\n",
    "| Layer | Daten | Beschreibung |\n",
    "|:---|:---|:---|\n",
    "| bike_accidents | Point (19557) | Unfalldaten nach Worfklow-Schritt 1, ohne abgeleitetes Tempolimit/RVA |\n",
    "| fis_rva | LineString (18641) | Vorprozessierter FIS-Broker Datensatz zu RVA |\n",
    "| fis_strassenabschnitte | LineString (43346) | Vorprozessierter FIS-Broker Datensatz zu Straßenabschnitten |\n",
    "| fis_tempolimit | LineString (29424) | Vorprozessierter FIS-Broker Datensatz zu Tempolimits |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a2fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike_acc = gpd.read_file(gpkg_src, layer='bike_accidents')\n",
    "df_roads = gpd.read_file(gpkg_src, layer='fis_strassenabschnitte')\n",
    "df_speed = gpd.read_file(gpkg_src, layer='fis_tempolimit')\n",
    "df_rva = gpd.read_file(gpkg_src, layer='fis_rva')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ab41f9",
   "metadata": {},
   "source": [
    "### Schritt 1.4: Spalten umbenennen/löschen\n",
    "\n",
    "Für dieses Notebook nicht benötigte Attribute werden gelöscht und Spaltennamen aus verschiedenen Datensatzen werden vereinheitlicht bzw. umbenannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859f7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns that aren't required for further processing\n",
    "df_bike_acc.drop(['ULAND', 'UKREIS', 'UGEMEINDE', 'OBJECTID'], axis=1, inplace=True)\n",
    "df_bike_acc_buf = df_bike_acc.copy()\n",
    "df_bike_acc_buf.drop(['UKATEGORIE', 'UART', 'UTYP1',\n",
    "                      'IstRad', 'IstPKW', 'IstFuss', 'IstKrad', 'IstGkfz', 'IstSonstig'], axis=1, inplace=True)\n",
    "df_roads.drop(['strassenna', 'str_bez', 'strassenkl', 'strassen_1', 'strassen_2', 'verkehrsri'], axis=1, inplace=True)\n",
    "df_rva.drop(['sobj_kz', 'segm_segm', 'rva_typ', 'sorvt_typ', 'b_pflicht'], axis=1, inplace=True)\n",
    "\n",
    "# rename columns\n",
    "df_speed.rename(columns={'elem_nr': 'element_nr'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ba071",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95d51d",
   "metadata": {},
   "source": [
    "## Daten vorbereiten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e6ec3c6",
   "metadata": {},
   "source": [
    "### Schritt 2.1: Initiales Puffern der Linien- bzw. Punktdaten als Vorbereitung für Spatial Joins\n",
    "\n",
    "- Unfälle: 10m\n",
    "- Straßenabschnitte und Tempolimits: 15m\n",
    "- RVA: 5m\n",
    "\n",
    "*(Hinweis: Die Puffergrößen wurden frei gewählt und sind das Ergebnis vielfältiger Tests. Diese Kombinationen haben insgesamt zu den besten Ergebnissen geführt)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924bb8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create buffer for road/RVA segments and accidents to find a good match\n",
    "# -> smaller buffer for RVA since each lane is captured separately\n",
    "df_bike_acc_buf['geometry'] = df_bike_acc_buf['geometry'].buffer(10, resolution=2)\n",
    "df_roads['geometry'] = df_roads['geometry'].buffer(15, resolution=2, cap_style=2)\n",
    "df_speed['geometry'] = df_speed['geometry'].buffer(15, resolution=2, cap_style=2)\n",
    "df_rva['geometry'] = df_rva['geometry'].buffer(5, resolution=2, cap_style=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7597a52",
   "metadata": {},
   "source": [
    "### Schritt 2.2: Gepufferte Geodaten in eigenes GeoPackage `map_data_buffered.gpkg` schreiben, um spätere Analysen zu ermöglichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8dc00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roads.to_file(gpkg_out, layer='buf_roads', driver='GPKG')\n",
    "df_speed.to_file(gpkg_out, layer='buf_speed', driver='GPKG')\n",
    "df_rva.to_file(gpkg_out, layer='buf_rva', driver='GPKG')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f2e7dbb",
   "metadata": {},
   "source": [
    "### Schritt 2.3: Datenselektion\n",
    "\n",
    "Im vorherigen Workflow-Schritt wurden u.a. basierend auf dem Straßentyp/-klasse ein Rang für jeden **Straßenabschnitt** ermittelt:\n",
    "\n",
    "- `0`: nicht relevant für Fahrradunfälle (z.B. Autobahn)\n",
    "- `1`: Priorität (z.B. Park, Grünanlage, Waldweg, …) &rarr; hier gilt keine Default-Geschwindigkeit\n",
    "- `2`: (nicht `0`, `1` oder `3`)\n",
    "- `3`: Priorität (z.B. Bundesstraßen, Gemeindestraßen, …) &rarr; hier gilt eine Default-Geschwindigkeit innerorts von 50km/h\n",
    "\n",
    "Sowohl der Datensatz für die Straßenabschnitte, als auch der Datensatz für das Tempolimit, enthalten ein Attribute `element_nr`, welches den Straßenabschnitt eindeutig identifiziert. Mittels `merge(..., on=\"element_nr\")` können somit die Ränge aus den Straßenabschnitten zu den dazugehörigen Tempolimits ermittelt werden.\n",
    "\n",
    "Anschließend können die Datensätze reduziert werden:\n",
    "- Tempolimits\n",
    "    - Abschnitte mit Rang `0` löschen &rarr; auf Autobahnen sind keine Fahrradunfälle zu erwarten; falls nicht gelöscht könnten diese jedoch das Ergebnis verfälschen (z.B. wenn Fahrradunfall auf Über-/Unterführung der Autobahn passiert)\n",
    "    - Datensätze ohne Angabe der zulässigen Höchstgeschwindigkeit löschen &rarr; Geschwindigkeit notwendig für weitere Verarbeitung\n",
    "- Straßenabschnitte\n",
    "    - Abschnitte mit Rang `0` löschen &rarr; siehe oben\n",
    "    - Abschnitte mit Rang `1` löschen &rarr; hierfür gelten keine Default-Geschwindigkeiten, d.h. diese sind für die weitere Verarbeitung nicht relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a14105aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - speed: ignore road rank '0' (e.g. Autobahn) and records without speed limit\n",
    "# - roads: ignore road rank '0' (e.g. Autobahn) and '1' (e.g. park, KGA, ...)\n",
    "df_speed = pd.merge(df_speed, df_roads[['element_nr', 'rank']], how='left', on=\"element_nr\")\n",
    "df_speed = df_speed.loc[df_speed['rank'] != 0]\n",
    "df_speed = df_speed.dropna(subset=['wert_ves'])\n",
    "df_roads = df_roads.loc[df_roads['rank'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed6672",
   "metadata": {},
   "source": [
    "### Schritt 2.4: Subsetting\n",
    "\n",
    "Das Tempolimit wird aus der Kombination zweier Datensätze ermittelt:\n",
    "\n",
    "1. Straßenabschnitte-Datensatz mit einer Default-Geschwindigkeit von 50km/h für Räng `2` und `3`\n",
    "2. Tempolimit-Datensatz mit zulässiger Höchstgeschwindigkeit als eigenes Attribut\n",
    "\n",
    "Da die beiden Datensätze nicht disjunkt sind, muss eine Überlagerung vermieden werden. Daher werden insgesamt drei Subsets von Straßenabschnitten gebildet:\n",
    "\n",
    "1. Abschnitte **ohne** Tempolimit &rarr; Straßenabschnitte-Datensatz abzgl. der Straßenabschnitte, die im Tempolimit-Datensatz über passende `element_nr` vorhanden sind\n",
    "2. Abschnitte **mit** Tempolimit &rarr; entspricht Tempolimit-Datensatz\n",
    "3. Abschnitte **mit partiellem** Tempolimit &rarr; Spezialfall, wenn Tempolimit eine zum Straßenabschnitt passende `element_nr` hat, der Abschnitt des Tempolimits jedoch kürzer ist als der gesamte Streckenabschnitt &rarr; wird in einem späteren Schritt ermittelt (`df_acc_rem`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21229dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce roads by matching entries found in speed limits dataset (matching 'element_nr')\n",
    "df_roads_wo_speed_idx = pd.concat(\n",
    "    [df_roads['element_nr'], df_speed['element_nr'], df_speed['element_nr']]).drop_duplicates(keep=False)\n",
    "df_roads_wo_speed = df_roads.loc[df_roads['element_nr'].isin(df_roads_wo_speed_idx.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886b043",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b06f00",
   "metadata": {},
   "source": [
    "## Spatial Joins: Tempolimits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b0d3f",
   "metadata": {},
   "source": [
    "### Schritt 3.1: Unfälle x Abschnitte ohne Tempolimit &rarr; `df_acc_x_road_wo_speed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c0b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join (1): bike accidents for all roads without speed limit\n",
    "# -> drop duplicates by considering road rank (highest ranked road 'wins')\n",
    "df_acc_x_road_wo_speed = gpd.sjoin(df_bike_acc_buf, df_roads_wo_speed, how='inner', predicate='intersects',\n",
    "                                   rsuffix='road')\n",
    "df_acc_x_road_wo_speed = df_acc_x_road_wo_speed.sort_values(['rank'], ascending=False).drop_duplicates(subset=['GUID'],\n",
    "                                                                                                       keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f3310b",
   "metadata": {},
   "source": [
    "### Schritt 3.2: Unfälle x Abschnitte mit Tempolimit &rarr; `df_acc_x_speed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe01f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join (2): bike accidents for all roads with speed limit\n",
    "df_acc_x_speed = gpd.sjoin(df_bike_acc_buf, df_speed, how='inner', predicate='intersects', rsuffix='speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbbc1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all accidents that have been found so far (roads with or without speed limit)\n",
    "df_concat = pd.concat([df_acc_x_road_wo_speed, df_acc_x_speed], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663f496",
   "metadata": {},
   "source": [
    "### Schritt 3.3: Unfälle x Abschnitte mit partiellem Tempolimit &rarr; `df_acc_rem_x_road`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa14f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specialty: speed limits sometimes don't cover the entire length of the road, although they have matching IDs\n",
    "# -> some roads have been ignored in spatial join (1) because it was assumed intersect was found in speed limit DF\n",
    "# -> extract those missing entries and spatial join (3) again with roads\n",
    "df_acc_rem_guid = pd.concat([df_bike_acc_buf['GUID'], df_concat['GUID']]).drop_duplicates(keep=False)\n",
    "df_acc_rem = df_bike_acc_buf.loc[df_bike_acc_buf['GUID'].isin(df_acc_rem_guid.values)]\n",
    "df_acc_rem_x_road = gpd.sjoin(df_acc_rem, df_roads, how='left', predicate='intersects', rsuffix='road')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d23984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append/concat remaining accidents\n",
    "df_concat = pd.concat([df_concat, df_acc_rem_x_road], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f8270",
   "metadata": {},
   "source": [
    "**&rarr; Zwischenergebnis**: jedem Unfall wurden die jeweils relevanten Streckenabschnitte aus den beiden Datensätzen (Straßenabschnitte bzw. Tempolimits) zugeordet &rarr; `df_concat`\n",
    "\n",
    "*(Hinweis: mit Außnahme der Unfälle, die nicht auf kartierten Straßenabschnitten passiert sind)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248a69e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f703d",
   "metadata": {},
   "source": [
    "## Tempolimit ableiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e2b50",
   "metadata": {},
   "source": [
    "### Schritt 4.1: Tempolimit aus Streckenabschnitt ableiten &rarr; Funktion `deriveSpeedLimit()` (vgl. Schritt 1.1)\n",
    "\n",
    "Nachdem jedem Unfall via Spatial Join mind. ein Streckenabschnitt zugeordnet wurde, muss aus dem jeweiligen Streckenabschnitt das zum Unfallzeitpunkt gültige Tempolimit abgeleitet werden. Dabei wird berücksichtigt:\n",
    "\n",
    "- Typ des Streckenabschnitts\n",
    "- Datum der Einführung des Tempolimits\n",
    "- Gültigkeit des Tempolimits (Einschränkung nach Wochentag und/oder Uhrzeit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efee79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['speed_der'] = df_concat.apply(deriveSpeedLimit, axis=1).astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1644f",
   "metadata": {},
   "source": [
    "### Schritt 4.2: Duplikate entfernen\n",
    "\n",
    "Zu diesem Zeitpunkt kann es sein, dass ein Unfall mehreren Streckenabschnitten zugeordnet ist (z.B. aufgrund Kreuzung). In diesem Fall wird der Streckenabschnitt mit der **höchsten** Geschwindigkeit beibehalten, alle anderen werden gelöscht &rarr; `df_concat_u`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dac968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since accidents at intersections have multiple road matches\n",
    "# -> drop duplicates (road with the highest speed limit 'wins')\n",
    "# -> remove unnecessary columns\n",
    "# -> count nan values (no speed limit derived)\n",
    "df_concat_u = df_concat.sort_values(['speed_der'], ascending=False).drop_duplicates(subset=['GUID'], keep='first')\n",
    "df_concat_u.drop(['index_road', 'index_speed', 'zeit_t', 'tag_t', 'dat_t', 'laenge'], axis=1, inplace=True)\n",
    "nan_count_speed = df_concat_u['speed_der'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0de417f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Unfälle, für die kein Tempolimit ermittelt werden konnte: 23\n"
     ]
    }
   ],
   "source": [
    "print(f'Anzahl Unfälle, für die kein Tempolimit ermittelt werden konnte: {nan_count_speed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf8e65",
   "metadata": {},
   "source": [
    "### Schritt 4.3: Unfalldaten inkl. Tempolimit werden GeoPackage hinzugefügt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3818724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 10m buffered accidents (incl. speed limit)\n",
    "df_concat_u.to_file(gpkg_out, layer='buf_acc_speed', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95320998",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c04fb",
   "metadata": {},
   "source": [
    "## Spatial Joins: RVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53e6be",
   "metadata": {},
   "source": [
    "### Schritt 5.1: Puffer anpassen\n",
    "\n",
    "Da RVA im Gegensatz zu Straßenabschnitten und Tempolimits richtungsabhängig sind, wird der Puffer von Unfällen um -5m auf insgesamt 5m angepasst. Somit ergibt sich:\n",
    "\n",
    "- Unfälle: 5m\n",
    "- RVA: 5m\n",
    "\n",
    "*(Hinweis: Die Puffergrößen wurden frei gewählt und sind das Ergebnis vielfältiger Tests. Diese Kombination hat insgesamt zu den besten Ergebnissen geführt)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72120dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dataframe and reduce buffer of accidents\n",
    "df_acc = df_concat_u.copy()\n",
    "df_acc['geometry'] = df_acc['geometry'].buffer(-5, resolution=2, cap_style=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9cfb4",
   "metadata": {},
   "source": [
    "### Schritt 5.2: Unfälle x RVA &rarr; `df_acc_x_rva`\n",
    "\n",
    "Da in diesem Fall die Daten nicht aus mehreren Datensätzen kombiniert werden müssen, reicht ein einfacher Spatial Join. \n",
    "\n",
    "Auch hier kann es dazu kommen, dass ein Unfall mehreren RVA zugeordnet wird. In diesem Fall wird die RVA mit dem **niedrigesten** Rang beibehalten, alle anderen werden gelöscht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2862e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join with RVA\n",
    "# -> drop duplicates (RVA with lowest rank/safety 'wins')\n",
    "# -> remove unnecessary columns\n",
    "# -> replace nan values to keep accidents where no RVA could be found\n",
    "df_acc_x_rva = gpd.sjoin(df_acc, df_rva, how='left', predicate='intersects', lsuffix='road', rsuffix='rva')\n",
    "df_acc_x_rva = df_acc_x_rva.sort_values(['rank_rva'], ascending=False).drop_duplicates(subset=['GUID'], keep='last')\n",
    "df_acc_x_rva.drop(['index_rva'], axis=1, inplace=True)\n",
    "df_acc_x_rva['rank_rva'].fillna(0, inplace=True)\n",
    "df_acc_x_rva['rank_rva'] = df_acc_x_rva['rank_rva'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d6211",
   "metadata": {},
   "source": [
    "### Schritt 5.3: Unfalldaten inkl. RVA werden GeoPackage hinzugefügt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "111bf5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 5m buffered accidents (incl. RVA)\n",
    "df_acc_x_rva.to_file(gpkg_out, layer='buf_acc_rva', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3f462",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22246dd3",
   "metadata": {},
   "source": [
    "## Punktdaten zu den Unfällen erweitern &rarr; `df_bike_acc_out`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec35c3",
   "metadata": {},
   "source": [
    "### Schritt 6.1: Initialen Unfall-Datensatz um ermitteltes Tempolimit und RVA erweitern (`merge`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "112e6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike_acc_out = pd.merge(df_bike_acc, df_concat_u[['GUID', 'speed_der']])\n",
    "df_bike_acc_out = pd.merge(df_bike_acc_out, df_acc_x_rva[['GUID', 'rank_rva']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c6e39",
   "metadata": {},
   "source": [
    "### Schritt 6.2: Unfälle kennzeichnen, bei denen die Geschwindigkeit relevant ist\n",
    "\n",
    "Dazu zählen Fahrradunfälle, wo außerdem folgende Verkehrsteilnehmer beteiligt waren:\n",
    "\n",
    "- Unfälle mit PKW\n",
    "- Unfälle mit Krad\n",
    "- Unfälle mit Güterkraftfahrzeug (z.B. LKW)\n",
    "- Unfälle mit Sonstigen (z.B. Bus, Tram, ...)\n",
    "\n",
    "Bei anderen Verkehrsteilnehmern, wie z.B. Unfall mit Fußgängern, ist das Tempolimit an der Unfallstelle für die weitere Auswertung nicht relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cff1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike_acc_out['speed_rel'] = np.where((df_bike_acc_out['IstPKW'] == 1) |\n",
    "                                        (df_bike_acc_out['IstKrad'] == 1) |\n",
    "                                        (df_bike_acc_out['IstGkfz'] == 1) |\n",
    "                                        (df_bike_acc_out['IstSonstig'] == 1),\n",
    "                                        True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ef36f1",
   "metadata": {},
   "source": [
    "### Schritt 6.3:  Unfalldaten inkl. Tempolimit und RVA werden GeoPackage `map_data.gpkg` hinzugefügt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e462ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike_acc_out.to_file(gpkg_src, layer='bike_accidents_ext', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
