{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b53e922",
   "metadata": {},
   "source": [
    "# Bildung von Unfall-Clustern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1f91d",
   "metadata": {},
   "source": [
    "## Initialisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4b4d7",
   "metadata": {},
   "source": [
    "### Import von Paketen und Definition von Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a887aa5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import configparser\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "from esda.adbscan import ADBSCAN, get_cluster_boundary, remap_lbls\n",
    "import contextily as cx\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # ignore warnings\n",
    "\n",
    "\n",
    "# function definitions\n",
    "def getClusters(gdf, eps, min_samples):\n",
    "    adbs = ADBSCAN(eps, min_samples, pct_exact=0.5, reps=10, keep_solus=True)\n",
    "    np.random.seed(1234)\n",
    "    adbs.fit(gdf)\n",
    "    return get_cluster_boundary(adbs.votes[\"lbls\"], gdf, crs=gdf.crs)\n",
    "  \n",
    "    \n",
    "def extendClusters(gdf, polys):\n",
    "    # Convert GeoSeries to GeoDataFrame\n",
    "    polys_gdf = gpd.GeoDataFrame(geometry=polys)\n",
    "    \n",
    "    # spatial join\n",
    "    polys_x_acc = gpd.sjoin(gdf, polys_gdf, how='inner', predicate='intersects')\n",
    "    \n",
    "    # Aggregation and join\n",
    "    res = polys_x_acc.groupby(['index_right'])['index_right'].count()\n",
    "    polys_gdf = polys_gdf.join(res)\n",
    "    polys_gdf.rename(columns={'index_right': 'accident_cnt'}, inplace=True)\n",
    "  \n",
    "    # determine coords\n",
    "    polys_gdf['coords'] = polys_gdf['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "    polys_gdf['coords'] = [coords[0] for coords in polys_gdf['coords']]\n",
    "    \n",
    "    return polys_gdf\n",
    "\n",
    "\n",
    "def showClusters(gdf, title, figsize):\n",
    "    # plot size\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "    \n",
    "    # add clusters as polygons\n",
    "    ax = gdf.plot(alpha=0.5, color=\"red\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # add number of accidents as polygon label\n",
    "    for idx, row in gdf.iterrows():\n",
    "        plt.annotate(text=row['accident_cnt'], xy=row['coords'], \n",
    "                     horizontalalignment='center', color='white', weight='bold', \n",
    "                     path_effects=[pe.withStroke(linewidth=1, foreground='black')]\n",
    "                    )\n",
    "    \n",
    "    # add basemap\n",
    "    cx.add_basemap(ax, crs=gdf.crs.to_string(), source=cx.providers.Stamen.TonerLite)\n",
    "    \n",
    "\n",
    "def exportClusters(gdf, layer_name):\n",
    "    # final prep + export\n",
    "    gdf.drop(['coords'], axis=1, inplace=True) \n",
    "    gdf.to_file(gpkg_cluster, layer=layer_name, driver='GPKG')\n",
    "    \n",
    "    \n",
    "def executeClustering(gdf, eps, min_samples, title, figsize, layer_name):\n",
    "    # Get clusters\n",
    "    print(f'Number of accidents: {len(gdf)}')\n",
    "    polys = getClusters(gdf, eps, min_samples)\n",
    "\n",
    "    # determine cluster attributes\n",
    "    clusters = extendClusters(gdf, polys)\n",
    "\n",
    "    # Show clusters on map\n",
    "    print(f'Number of clusters: {len(clusters)}')\n",
    "    showClusters(clusters, title, figsize)\n",
    "\n",
    "    # export clusters to GeoPackage\n",
    "    exportClusters(clusters, layer_name)\n",
    "    print(f'GeoPackage updated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f657db",
   "metadata": {},
   "source": [
    "### Laden der Konfiguration aus der `config.ini`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d72c03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rel_path = './../'\n",
    "\n",
    "# read local config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(rel_path + 'config.ini')\n",
    "\n",
    "# get from config.ini\n",
    "dir_output = rel_path + config['FILE_SETTINGS']['DIR_OUTPUT']\n",
    "gpkg_src = dir_output + config['FILE_SETTINGS']['GPKG_NAME']\n",
    "gpkg_cluster = dir_output + config['FILE_SETTINGS']['GPKG_NAME_CLU']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93e9f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Laden der Unfalldaten\n",
    "\n",
    "Die Unfalldaten wurden in den vorherigen Workflow-Schritten verarbeitet und aufbereitet, um diese hinsichtlich des Tempolimits und der Radverkehrsanlagen analysieren zu können.\n",
    "\n",
    "Die Daten befinden sich im dafür erstellen GeoPackage `map_data.gpkg` mit folgenden Layern:\n",
    "\n",
    "| Layer | Daten | Beschreibung |\n",
    "|:---|:---|:---|\n",
    "| bike_accidents | Point (19557) | Unfalldaten nach Worfklow-Schritt 1, ohne abgeleitetes Tempolimit/RVA |\n",
    "| **bike_accidents_ext** | **Point (19557)** | **Aufbereitete Unfalldaten nach Worfklow-Schritt 2, erweitert um Tempolimit/RVA** |\n",
    "| fis_rva | LineString (18641) | Vorprozessierter FIS-Broker Datensatz zu RVA |\n",
    "| fis_strassenabschnitte | LineString (43346) | Vorprozessierter FIS-Broker Datensatz zu RVA |\n",
    "| fis_tempolimit | LineString (29424) | Vorprozessierter FIS-Broker Datensatz zu Tempolimits |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf961b",
   "metadata": {},
   "source": [
    "Es werden nur die für die Cluster-Analyse notwendigen Daten geladen, um die Verarbeitungszeit zu beschleunigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c2fc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read preprocessed files\n",
    "gdf = gpd.read_file(gpkg_src, layer='bike_accidents_ext', \n",
    "                   ignore_fields=['UJAHR', 'UMONAT', 'USTUNDE', 'UWOCHENTAG', \n",
    "                                  'UART', 'UTYP1', \n",
    "                                  'IstRad', 'IstPKW', 'IstFuss', 'IstKrad', 'IstGkfz', 'IstSonstig'\n",
    "                                 ])\n",
    "\n",
    "# get coords\n",
    "gdf[\"X\"] = gdf.geometry.x\n",
    "gdf[\"Y\"] = gdf.geometry.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e8d9e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Cluster Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9805b28",
   "metadata": {},
   "source": [
    "**Ablauf**: für jede Cluster Map werden die folgende Schritte durchgeführt:\n",
    "\n",
    "1. Selektion der Daten\n",
    "2. `ADBSCAN` (**A**daptive **D**ensity-**B**ased **S**patial **C**lustering of **A**pplications with **N**oise), um Cluster in Form von Polygonen zu erhalten\n",
    "3. Unfälle pro Polygon und Polygon-Koordinaten ermitteln\n",
    "    - Ermittlung der im Polygon enthaltenen Unmfälle mittels Spatial Join (`how=inner` und `predicate=intersects`)\n",
    "    - Aggregation (`groupby()` und `count()`)\n",
    "4. Darstellung der Polygone auf einer Karte (inkl. Anzahl der Unfälle innerhalb des Polygons)   \n",
    "5. Export als GeoPackage (eigener Layer pro Cluster Map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03429bc5",
   "metadata": {},
   "source": [
    "## Alle Fahrradunfälle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "executeClustering(gdf, 200, 75, 'Alle Unfälle', [12, 15], 'acc_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b8b16d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Geschwindigkeitsrelevante Fahrradunfälle auf Straßen, wo das Tempolimit mehr als 30km/h beträgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c9ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sel = gdf.loc[gdf['speed_rel'] & (gdf['speed_der'] > 30)]\n",
    "\n",
    "executeClustering(gdf_sel, 200, 50, 'Unfälle mit Tempolimit >30 km/h', [15, 10], 'acc_no_speedlimit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30203b1a",
   "metadata": {},
   "source": [
    "## Fahrradunfälle auf Straßen ohne Radverkehrsanlagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3495848",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sel = gdf.loc[gdf['rank_rva'] == 0]\n",
    "\n",
    "executeClustering(gdf_sel, 150, 40, 'Unfälle ohne RVA', [15, 12], 'acc_no_rva')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d61fe94",
   "metadata": {},
   "source": [
    "## Geschwindigkeitsrelevante Fahrradunfälle auf Straßen, wo das Tempolimit mehr als 30km/h beträgt und keine Radverkehrsanlagen vorhanden sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sel = gdf.loc[gdf['speed_rel'] & (gdf['speed_der'] > 30) & (gdf['rank_rva'] == 0)]\n",
    "\n",
    "executeClustering(gdf_sel, 150, 25, 'Unfälle ohne RVA und Tempolimit >30 km/h', [15, 15], 'acc_no_rva_no_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a7a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
